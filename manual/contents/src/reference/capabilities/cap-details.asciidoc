[[capabilities]]
Capabilities
============

[[capabilities-data-security]]
== Data Security ==

Some data may need to be protected from unauthorized access (e.g., theft, modification). 
Neo4j does not deal with data encryption explicitly, but supports all means built into the Java programming language and the JVM to protect data by encrypting it before storing.

Furthermore, data can be easily secured by running on an encrypted datastore at the file system level.
Finally, data protection should be considered in the upper layers of the surrounding system in order to prevent problems with scraping, malicious data insertion, and other threats.

[[capabilities-data-integrity]]
== Data Integrity ==

In order to keep data consistent, a good database needs mechanisms and
structures that guarantee the integrity of all stored data. In Neo4j, data
integrity is guaranteed both for graph elements (Nodes, Relationships and
Properties) and for non-graph data, such as the indexes. Neo4j's transactional
architecture ensures that data is protected and provides for fast recovery from
an unexpected failure, without the need to rebuild internal indexes or other
costly operations.

[[capabilities-data-integration]]
== Data Integration ==

Most enterprises rely primarily on relational databases to store their data, but 
this may cause performance limitations.
In some of these cases, Neo4j can be used as an extension to supplement search/lookup for faster decision making.
However, in any situation where multiple data repositories contain the same data, synchronization can be an issue.

In some applications, it is acceptable for the search platform to be slightly out 
of sync with the relational database.
In others, tight data integrity (eg., between Neo4j and RDBMS) is necessary. 
Typically, this has to be addressed for data changing in real-time and for bulk data changes happening in the RDBMS.

A few strategies for synchronizing integrated data follows.

[[capabilities-event-based-synchronization]]
=== Event-based Synchronization ===

In this scenario, all data stores, both RDBMS and Neo4j, are fed with domain-specific 
events via an event bus.
Thus, the data held in the different backends is not actually synchronized but rather replicated.

[[capabilities-periodic-synchronization]]
=== Periodic Synchronization ===

Another viable scenario is the periodic export of the latest changes in the RDBMS to 
Neo4j via some form of SQL query.
This allows a small amount of latency in the synchronization, but has the advantage of using the RDBMS as the master for all data purposes.
The same process can be applied with Neo4j as the master data source.

[[capabilities-full-export]]
=== Periodic Full Export/Import of Data ===

Using the Batch Inserter tools for Neo4j, even large amounts of data can be imported 
into the database in very short times.
Thus, a full export from the RDBMS and import into Neo4j becomes possible.
If the propagation lag between the RDBMS and Neo4j is not a big issue, this is a very viable solution.

[[capabilities-availability]]
== Availability and Reliability ==

Most mission-critical systems require the database subsystem to be accessible at all 
times.
Neo4j ensures availability and reliability through a few different strategies.  

[[capabilities-op-availability]]
=== Operational Availability ===

In order not to create a single point of failure, Neo4j supports different 
approaches which provide transparent fallback and/or recovery from failures.

==== Online backup (Cold spare) ====

In this approach, a single instance of the master database is used, with Online 
Backup enabled.
In case of a failure, the backup files can be mounted onto a new 
Neo4j instance and reintegrated into the application.

==== Online Backup High Availability (Hot spare) ====

Here, a Neo4j "backup" instance listens to online transfers of changes from the 
master.
In the event of a failure of the master, the backup is already running 
and can directly take over the load.

==== High Availability cluster ====

This approach uses a cluster of database instances, with one (read/write) master 
and a number of (read-only) slaves.
Failing slaves can simply be restarted and brought back online.
Alternatively, a new slave may be added by cloning an existing one.
Should the master instance fail, a new master will be elected by the remaining 
cluster nodes.

[[capabilities-disaster]]
=== Disaster Recovery/ Resiliency ===

In cases of a breakdown of major part of the IT infrastructure, there need to be 
mechanisms in place that enable the fast recovery and regrouping of the remaining 
services and servers.
In Neo4j, there are different components that are suitable to be part of a disaster recovery strategy.

==== Prevention ====

* Online Backup High Availability to other locations outside the current data center.
* Online Backup to different file system locations: this is a simpler form of backup, 
applying changes directly to backup files; it is thus more suited for local backup scenarios.
* Neo4j High Availability cluster: a cluster of one write-master Neo4j server and a number of read-slaves, getting transaction logs from the master.
  Write-master failover is handled by quorum election among the read-slaves for a new master.

==== Detection ====

* SNMP and JMX monitoring can be used for the Neo4j database.

==== Correction ====

* Online Backup: A new Neo4j server can be started directly on the backed-up files 
and take over new requests.
* Neo4j High Availability cluster: A broken Neo4j read slave can be reinserted into the cluster, getting the latest updates from the master.
  Alternatively, a new server can be inserted by copying an existing server and applying the latest updates to it.

[[capabilities-capacity]]
== Capacity ==

[[capabilities-file-sizes]]
=== File Sizes ===

Neo4j relies on Java's Non-blocking I/O subsystem for all file handling.
Furthermore, while the storage file layout is optimized for interconnected data, Neo4j does not require raw devices.
Thus, file sizes are only limited by the underlying operating system's capacity to handle large files.
Physically, there is no built-in limit of the file handling capacity in Neo4j.

Neo4j has a built-in page cache, that will cache the contents of the storage files.
If there is not enough RAM to keep the storage files resident, then Neo4j will page parts of the files in and out as necessary, while keeping the most popular parts of the files resident at all times.
Thus, ACID speed degrades gracefully as RAM becomes the limiting factor.

[[capabilities-read-speed]]
=== Read speed ===

Enterprises want to optimize the use of hardware to deliver the maximum business value from available resources.
Neo4j's approach to reading data provides the best possible usage of all available hardware resources.
Neo4j does not block or lock any read operations; thus, there is no danger for deadlocks in read operations and no need for read transactions.
With a threaded read access to the database, queries can be run simultaneously on as many processors as may be available.
This provides very good scale-up scenarios with bigger servers.

[[capabilities-write-speed]]
=== Write speed ===

Write speed is a consideration for many enterprise applications.
However, there are two different scenarios:

. sustained continuous operation and
. bulk access (e.g., backup, initial or batch loading).

To support the disparate requirements of these scenarios, Neo4j supports two modes of writing to the storage layer.

In transactional, ACID-compliant normal operation, isolation level is maintained and 
read operations can occur at the same time as the writing process.
At every commit, the data is persisted to disk and can be recovered to a consistent state upon system failures.
This requires disk write access and a real flushing of data.
Thus, the write speed of Neo4j on a single server in continuous mode is limited by the I/O capacity of the hardware.
Consequently, the use of fast SSDs is highly recommended for production scenarios.

Neo4j has a Batch Inserter that operates directly on the store files.
This mode does not provide transactional security, so it can only be used when there is a single write thread.
Because data is written sequentially, and never flushed to the logical logs, huge performance boosts are achieved.
The Batch Inserter is optimized for non-transactional bulk import of large amounts of data.  

[[capabilities-data-size]]
=== Data size ===

In Neo4j, data size is mainly limited by the address space of the primary keys for Nodes, Relationships, Properties and RelationshipTypes.
Currently, the address space is as follows:

|=========
| nodes | 2^35^ (&#8764; 34 billion) 
| relationships | 2^35^ (&#8764; 34 billion) 
| properties | 2^36^ to 2^38^ depending on property types (maximum &#8764; 274 billion, always at least &#8764; 68 billion)
| relationship types | 2^16^ (&#8764; 65 000)
|=========

